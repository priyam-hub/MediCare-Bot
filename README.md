<div align="center">

# ğŸ¤– MediCare-Bot â€” Your trusted health companion.

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/)
[![Flask](https://img.shields.io/badge/Flask-2.0+-orange.svg)](https://flask.palletsprojects.com/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![LLaMA 3](https://img.shields.io/badge/LLaMA-3%208B-purple.svg)](https://ai.meta.com/llama/)
[![Docker](https://img.shields.io/badge/Docker-Containerized-blue)](https://www.docker.com/)

*Supporting patients with trusted answers, one conversation at a time.*

[Features](#-features) â€¢ [Installation](#-installation) â€¢ [Usage](#-usage) â€¢ [Tech Stack](#-tech-stack) â€¢ [License](#-license) â€¢ [Contact](#-contact)

</div>

---

## ğŸŒŸ Overview

**MediCare-Bot** is designed to assist users with reliable and easy-to-understand health information. It learns from trusted medical books and uses intelligent search techniques to find the most relevant content. By combining smart retrieval with a powerful language model, the chatbot offers clear and accurate responses to medical queries, making healthcare information more accessible and conversational for everyone.

---

## ğŸ“š Dataset

**Source:** [Medical Book Dataset â€“ Kaggle](https://www.kaggle.com/datasets/abhirajmandal/medical-book)

#### ğŸ” Description

This dataset contains textual content extracted from medical books, designed to provide structured and informative knowledge on a wide range of medical topics. It includes concise explanations, definitions, symptoms, causes, and treatments for various diseases and conditions. The dataset is ideal for building knowledge-driven applications like medical chatbots, as it captures essential clinical and healthcare-related information in a digestible format.

**Use Case:**
The dataset serves as the foundational knowledge base for the chatbot, allowing it to generate helpful and accurate responses to user queries by referencing real medical literature.

---

## ğŸ“Œ Features

* **Patient-Centric Design**
  - Focused on delivering helpful and compassionate responses tailored to user needs.

* **Trusted Medical Knowledge**
  - Built using information from reliable medical books to ensure accuracy.

* **Natural Conversations**
  - Understands and responds in a human-like, conversational tone.

* **Instant Answers**
  - Provides quick and relevant responses to a wide range of medical questions.

* **Context-Aware**
  - Remembers and considers the context of your query for better responses.

* **User-Friendly Interface**
  - Simple and clean chat interface that's easy to use for everyone.

* **Secure and Private**
  - No personal data is stored or sharedâ€”ensuring privacy and confidentiality.

---

## ğŸ› ï¸ Installation

### Step - 1: Repository Cloning

```bash
# Clone the repository
git clone https://github.com/priyam-hub/MediCare-Bot.git

# Navigate into the directory
cd MediCare-Bot
```

### Step - 2: Enviornmental Setup and Dependency Installation

```bash
# Run env_setup.sh
bash env_setup.sh

# Select 1 to create Python Environment
# Select 2 to create Conda Environment

# Python Version - 3.10
```

### Step - 3: Create a .env file in the root directory to add Credentials

```bash
PINECONE_API_KEY = "xxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
GROQ_API_KEY  = "xxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
```

### Step - 4: Store the Vector Embeddings & Initialize RAG

```bash

# Run the Main Python Script
python main.py
```

### Step - 5: Run the Flask Server

```bash

# Run the Web App using Flask Server
python web/app.py
```

Upon running, navigate to the provided local URL in your browser to interact with the MediCare-Bot

---

## âš™ï¸ Technology Stack


* **Python** â€“ Core programming language used for building the backend.
  ğŸ”— [Install Python](https://www.python.org/downloads/)

* **PyTorch** â€“ Deep learning framework used under the hood for embedding models and LLMs.
  ğŸ”— [Install PyTorch](https://pytorch.org/get-started/locally/)

* **Transformers (Hugging Face)** â€“ Used to load and manage pre-trained embedding models.
  ğŸ”— [Transformers Documentation](https://huggingface.co/docs/transformers/index)

* **LangChain** â€“ Framework for building applications with LLMs, supporting RAG and vector search.
  ğŸ”— [LangChain Installation Guide](https://docs.langchain.com/docs/get_started/installation)

* **Flask** â€“ Lightweight web framework to deploy the chatbot as a web API.
  ğŸ”— [Flask Installation](https://flask.palletsprojects.com/en/latest/installation/)

---

### ğŸ§  Artificial Intelligence Models Stack

* **Vector Embedding â€“ `sentence-transformers/all-MiniLM-L6-v2`**
  Lightweight and efficient embedding model for generating semantic vector representations of medical texts.
  ğŸ”— [Model on Hugging Face](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)

* **Vector Database â€“ Pinecone**
  High-performance vector store to manage and search large-scale embedding data.
  ğŸ”— [Pinecone Documentation](https://docs.pinecone.io/docs/overview)

* **Information Retrieval â€“ RAG (Retrieval-Augmented Generation)**
  Augments LLM responses by retrieving relevant content from medical embeddings.
  ğŸ”— [RAG on LangChain](https://docs.langchain.com/docs/components/retrievers/)

* **Inference Engine â€“ Groq**
  Ultra-fast inference platform to run LLaMa-3 and generate real-time answers.
  ğŸ”— [Groq API](https://groq.com/)

* **Large Language Model â€“ LLaMa-3 8B**
  Advanced open-source language model from Meta used for understanding medical context and generating responses.
  ğŸ”— [LLaMa 3 (Meta)](https://ai.meta.com/llama/)

* **API Integration â€“ Flask**
  Handles user requests and chatbot interactions through a simple web API.
  ğŸ”— [Flask Official Docs](https://flask.palletsprojects.com/en/latest/)

* **Environmental Image â€“ Docker**
  Ensures consistent, portable, and isolated runtime environment for the chatbot application.
  ğŸ”— [Docker Installation](https://docs.docker.com/get-docker/)

* **Deployment â€“ EC2 Instance**
  Scalable cloud server to host and serve the medical chatbot application.
  ğŸ”— [Amazon EC2](https://aws.amazon.com/ec2/)

---

## ğŸ“ Project Structure

```plaintext
MediCare-Bot/
â”œâ”€â”€ .docker_ignore                            # Ignoring Files in Docker
â”œâ”€â”€ .env                                      # Store the Pinecone and Groq Credentials
â”œâ”€â”€ .gitignore                                # Ignoring files for Git
â”œâ”€â”€ Dockerfile                                # Stored the Docker Setup
â”œâ”€â”€ env_setup.sh                              # Package installation configuration
â”œâ”€â”€ folder_structure.py                       # Contains the Project Folder Structure
â”œâ”€â”€ LICENCE                                   # MIT License
â”œâ”€â”€ main.py                                   # Store Vector Embeddings and Initialize the RAG
â”œâ”€â”€ README.md                                 # Project documentation
â”œâ”€â”€ requirements.txt                          # Python dependencies
â”œâ”€â”€ setup.py                                  # Create the Project as Python Package
â”œâ”€â”€ config/                                   # Configuration files
â”‚   â”œâ”€â”€ __init__.py                           
â”‚   â””â”€â”€ config.py/                            # All Configuration Variables of Pipeline
â”œâ”€â”€ data/                                     # Data directory
â”‚   â””â”€â”€ Medical_Book.pdf                      # Medical Book Dataset used for Vector Embedding
â”œâ”€â”€ notebooks/                                # Jupyter notebooks for experimentation
â”‚   â””â”€â”€ Medical_Chatbot.ipynb                 # Experimented Chatbot in Jupyter Notebook
â”œâ”€â”€ src/                                      # Source code
â”‚   â”œâ”€â”€ llm/                                  # Large Language Model Directory
â”‚   â”‚   â”œâ”€â”€ __init__.py  
â”‚   â”‚   â””â”€â”€ llm_builder.py                    # Python file to Build the LLM using ChatGroq                                       
â”‚   â”œâ”€â”€ prompts/                              # System Prompt Directory
â”‚   â”‚   â”œâ”€â”€ __init__.py   
â”‚   â”‚   â””â”€â”€ prompt_builder.py                 # Python file Build the Prompt for LLM Inference                                   
â”‚   â”œâ”€â”€ text_splitting/                       # Text Splitting Directory
â”‚   â”‚   â”œâ”€â”€ __init__.py                           
â”‚   â”‚   â””â”€â”€ split_text.py                     # Python File to Split the Text                                    
â”‚   â”œâ”€â”€ vector_index/                         # Vector Index Directory
â”‚   â”‚   â”œâ”€â”€ __init__.py   
â”‚   â”‚   â””â”€â”€ index_manager.py                  # Python file to create index in Vector DB                                            
â”‚   â””â”€â”€ utils/                                # Utility Functions Directory
â”‚       â”œâ”€â”€ __init__.py                     
â”‚       â”œâ”€â”€ download_embeddings.py            # Download the Embedding Model
â”‚       â”œâ”€â”€ load_pdf.py                       # Load the PDF for Embedding
â”‚       â””â”€â”€ logger.py                         # Logger Setup
â””â”€â”€ web/
    â”œâ”€â”€ __init__.py  
    â”œâ”€â”€ animations/                           
    â”‚   â”œâ”€â”€ chatbot.json                      # Chatbot Animations
    â”‚   â””â”€â”€ doctor.json                       # Doctor Animations
    â”œâ”€â”€ static/                                
    â”‚   â”œâ”€â”€ style.css                         # Styling of the Web Page
    â”œâ”€â”€ templates/                                
    â”‚   â”œâ”€â”€ chat.html                         # Default Web Page
    â””â”€â”€ app.py/                               # To run the flask server
        
```









